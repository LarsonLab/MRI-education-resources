{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading image\n",
      "loading signal\n"
     ]
    }
   ],
   "source": [
    "% setup MRI-education-resources path and requirements\n",
    "cd ../\n",
    "startup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accelerated Imaging Methods (In Progress Page)\n",
    "\n",
    "MRI scans can be accelerated by applying methods that reduce the number of k-space samples required, also known as undersampling.  These require a corresponding advanced image reconstruction method to allow for the reduced sampling.  The techniques covered here include parallel imaging, compressed sensing, and deep learning methods. \n",
    "\n",
    "## Learning Goals\n",
    "\n",
    "1. Describe how images are formed\n",
    "    * Describe how accelerated imaging methods work\n",
    "1. Understand the constraints and tradeoffs in MRI\n",
    "    * Identify accelerated imaging methods\n",
    "    * Understand when accelerated imaging methods can be applied\n",
    "1. Manipulate MRI sequence parameters to improve performance\n",
    "    * Define which parameters are modified when accelerated imaging methods are applied\n",
    "1. Manipulate and analyze MRI data\n",
    "    * Reconstruct an image from undersampled raw data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formulating the Reconstruction Problem\n",
    "\n",
    "For image reconstruction, it is helpful to reformulate the MRI Signal Equation, which we can pose for MRI as a linear system and using standard mathematical notation describing systems as:\n",
    "\n",
    "$$ \\mathbf{y} = \\mathbf{Ex} + \\mathbf{n} $$\n",
    "\n",
    "where $\\mathbf{y}$ is the acquired data, $\\mathbf{E}$ is the encoding matrix, $\\mathbf{x}$ is the spatial distribution of the transverse magnetization (e.g. image), and $\\mathbf{n}$ is noise\n",
    "\n",
    "The encoding matrix, $E$, must include a discrete Fourier Transform matrix, representing our data is the Fourier Transform of the transverse magnetization, evaluated at k-space locations.  It should also include coil sensitivity profiles in order to support parallel imaging formulations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Formulation of MRI Reconstruction\n",
    "\n",
    "For advanced image reconstruction methods, it is helpful to reformulate the reconstruction problem as a linear system and using standard mathematical notation describing linear systems as:\n",
    "\n",
    "$$ \\mathbf{y} = \\mathbf{Ex} + \\mathbf{n} $$\n",
    "\n",
    "In 2D Cartesian\n",
    "\n",
    "vectorized data and images\n",
    "\n",
    "$$ y = \\left[ \n",
    "    \\begin{array}{c}\n",
    "s_1(t_1) \\\\\n",
    "s_1(t_2) \\\\\n",
    "\\vdots \\\\\n",
    "s_1(t_{Nx}) \\\\\n",
    "s_2(t_1) \\\\\n",
    "\\vdots \\\\\n",
    "s_{Ny}(t_{Nx})\\\\\n",
    "\\end{array}\n",
    "\\right]$$\n",
    "\n",
    "\n",
    "$$ x = \\left[ \n",
    "    \\begin{array}{c}\n",
    "m(x_1,y_1) \\\\\n",
    "m(x_2,y_1) \\\\\n",
    "\\vdots \\\\\n",
    "m(x_{Nx},y_1) \\\\\n",
    "m(x_{1},y_2) \\\\\n",
    "\\vdots \\\\\n",
    "m(x_{Nx},y_{Ny}) \n",
    "\\end{array}\n",
    "\\right]$$\n",
    "\n",
    "\n",
    "where $\\mathbf{y}$ is the acquired data, $\\mathbf{E}$ is the encoding matrix, $\\mathbf{x}$ is the spatial distribution of the transverse magnetization (e.g. image), and $\\mathbf{n}$ is noise\n",
    "\n",
    "The encoding matrix, $E$, must include a discrete Fourier Transform matrix, representing our data is the Fourier Transform of the transverse magnetization, evaluated at k-space locations.  It should also include coil sensitivity profiles in order to support parallel imaging formulations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Imaging\n",
    "\n",
    "For parallel imaging (PI), we need to consider the coil sensitivity profiles, $\\mathbf{C}$, into encoding matrix along with a Fourier Transform encoding matrix, $\\mathbf{F}$:\n",
    "\n",
    "$$\\mathbf{E} = \\mathbf{F} \\mathbf{C}$$\n",
    "\n",
    "### Image-space Methods\n",
    "Image-space parallel imaging methods (e.g. SENSE) can be formulated as the following optimization problem\n",
    "\n",
    "$$\\hat{x}_{PI} = \\arg \\min_\\mathbf{x} \\frac{1}{2} \\| \\mathbf{y} - \\mathbf{Ex} \\|^2_2$$ \n",
    "\n",
    "This can be solved directly by a pseudo-inverse, but requires measurements of the coil sensitivity profiles to calculate $\\mathbf{E}$:\n",
    "\n",
    "$$\\hat{x}_{PI} = (\\mathbf{E}^H\\mathbf{E})^{-1} \\mathbf{E}^H \\mathbf{y} $$\n",
    "\n",
    "The k-space sampling patterns used for these methods typically use regular undersampling, meaning there is a consistent pattern of acquired and skipped k-space lines.\n",
    "\n",
    "### K-space Methods\n",
    "\n",
    "K-space parallel imaging methods (e.g. GRAPPA) utilize a calibration kernel, computed from the data itself and captured in the matrix $\\mathbf{G}$.  These can also be generally formulated as the following optimization problem\n",
    "\n",
    "$$\\hat{x}_{PI} = \\arg \\min_\\mathbf{x} \\| \\mathbf{y} - \\mathbf{Ex} \\|^2_2 + \\lambda \\| (\\mathbf{G} - \\mathbf{I}) \\mathbf{x} \\|^2_2 $$\n",
    "\n",
    "Where $\\lambda$ is a tuning or regularization parameter and $\\mathbf{I}$ is the identity matrix.  This simultaneous enforces data consistency (first term) as well as self-consistency of the calibration (sescond term).\n",
    "\n",
    "The calibration kernel, $\\mathbf{G}$, can either be directly measured from the data as in GRAPPA, or iteratively estimated during the reconstruction.\n",
    "\n",
    "The k-space sampling patterns used for these methods typically use regular undersampling, meaning there is a consistent pattern of acquired and skipped k-space lines, combined with full sampling in the center of k-space.\n",
    "\n",
    "### SNR in Parallel Imaging\n",
    "\n",
    "Due to ill conditioning of the parallel imaging, there is an SNR penalty when using these methods.  This is characterized by the \"g-factor\", where $g \\geq 1$ characterizes the SNR loss that is dependent on the coil loading and geometry, k-space sampling pattern, and parallel imaging reconstruction method.  When appyling an acceleration factor of $R$, the total readout time reduces the SNR by $\\sqrt{R}$ as well, leading to the SNR relationship:\n",
    "\n",
    "$$SNR_{PI} = \\frac{SNR_{full}}{g\\sqrt{R}}$$\n",
    "\n",
    "### Artifacts with Parallel Imaging\n",
    "\n",
    "Parallel Imaging artifacts typically appear as aliasing.  The undersampled data will have aliasing when not using a parallel imaging reconstruction method, and sometimes the aliasing is not completely removed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compressed Sensing Methods\n",
    "\n",
    "Compressed Sensing (CS) theory says that an image that is compressible in some domain can then be reconstructed from a subset of data samples.  In other words, we can further accelerate our data acquisition.\n",
    "\n",
    "Compressed Sensing is formulated as the following optimization problem\n",
    "\n",
    "$$\\hat{x}_{CS} = \\arg \\min_\\mathbf{x} \\frac{1}{2} \\| \\mathbf{y} - \\mathbf{Ex} \\|^2_2 + \\lambda_{CS} \\| \\mathbf{Wx} \\|_1 $$\n",
    "\n",
    "which includes a data consistency term where the data multiplied by the encoding matrix must match the reconstructed image, and a regularization term that enforces that the image is sparse in some other domain through the sparsifying transform, $\\mathbf{W}$.  There is a regularization factor, $\\lambda_{CS}$, that must be chosen to balance the data consistency and sparsity terms.\n",
    "\n",
    "Popular sparsifying transforms include total variation (TV), total generalized variation (TGV), and wavelets.\n",
    "\n",
    "The k-space sampling patterns used for these methods typically use pseudo-random undersampling with a variable density that preferentially increases the number of samples near the center of k-space.\n",
    "\n",
    "### SNR in Compressed Sensing\n",
    "\n",
    "It is difficult to define SNR when using compressed sensing reconstruction methods, as they inherently perform some denoising when constraining the reconstruction based on sparsity.  The apparent SNR can also vary significantly depending on the choice of the regularization factor, $\\lambda_{CS}$.\n",
    "\n",
    "### Artifacts with Compressed Sensing\n",
    "\n",
    "The most common artifacts from compressed sensing come from overfitting to the sparsity penalty.  This result in either an over-smoothed appearance or, in the case of a wavelet sparsifying transform, blocking artifacts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network/Deep Learning Reconstructions\n",
    "\n",
    "Convolutional neural networks (CNNs), which form the backbone of deep learning (DL), can be used to convert k-space to image data from a subset of data samples as well.  Conceptually, these methods can be trained to learn how to incorporate coil sensitivity information like parallel imaging and typical image sparsity patterns like compressed sensing.  Since they learn from real-world data, they can learn information that is the most relevant to MRI data and thus have been shown to support higher acceleration factors. \n",
    "\n",
    "Perhaps the most popular class of DL reconstruction methods for MRI are so-called \"un-rolled\" networks.  This term confirms \n",
    "\n",
    "Compressed Sensing is formulated as the following optimization problem\n",
    "\n",
    "$$\\hat{x}_{CS} = \\arg \\min_\\mathbf{x} \\frac{1}{2} \\| \\mathbf{y} = \\mathbf{Ex} \\|^2_2 +\\tau \\| \\mathbf{Wx} \\|_1 $$\n",
    "\n",
    "which includes a data consistency term where the data multiplied by the encoding matrix must match the reconstructed image, and a regularization term that enforces that the image is sparse in some other domain through the sparsifying transform, $\\mathbf{W}$.\n",
    "\n",
    "Popular sparsifying transforms include total variation (TV), total generalized variation (TGV), and wavelets.\n",
    "\n",
    "The k-space sampling patterns used for these methods typically use pseudo-random undersampling with a variable density that preferentially increases the number of samples near the center of k-space\n",
    "\n",
    "\n",
    "### SNR in Compressed Sensing\n",
    "\n",
    "### Artifacts with Compressed Sensing\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Octave",
   "language": "octave",
   "name": "octave"
  },
  "language_info": {
   "file_extension": ".m",
   "help_links": [
    {
     "text": "GNU Octave",
     "url": "https://www.gnu.org/software/octave/support.html"
    },
    {
     "text": "Octave Kernel",
     "url": "https://github.com/Calysto/octave_kernel"
    },
    {
     "text": "MetaKernel Magics",
     "url": "https://metakernel.readthedocs.io/en/latest/source/README.html"
    }
   ],
   "mimetype": "text/x-octave",
   "name": "octave",
   "version": "5.1.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e6d0a785abadc7cb3a62b253cac00443a0668af2186e6de66a25d59b1ad5cbbd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
